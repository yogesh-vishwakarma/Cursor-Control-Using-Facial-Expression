# Cursor-Control-Using-Facial-Expression
a novel camera mouse driven by 2D model based visual face tracking technique
Using tools
dlib
imutils
opencv
numpy


This proposed project introduces a novel camera mouse
driven by 2D model based visual face tracking
technique. While camera becomes standard
configuration for personal computer (PC) and
computer speed becomes faster and faster,
achieving human machine interaction through
visual face tracking becomes a feasible solution
to hand-free control. The human facial movement
can be decomposed into rigid movement, e.g.
rotation and translation, and non-rigid movement,
such as the open/close of mouth, eyes, and facial
expressions, etc. We introduce our visual face
tracking system that can robustly and accurately
retrieve these motion parameters from video at
real-time. After calibration, the retrieved head
orientation and translation can be employed to
navigate the mouse cursor, and the detection of
mouth movement can be utilized to trigger mouse
events.This technique can be an alternative input device for
people with hand and speech disability and for
futuristic vision-based game and interface.
